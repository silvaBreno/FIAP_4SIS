# Arquiteturas paralelas

Exercícios SpeedUp e Eficiência

> O terceiro fator é que com o passar do tempo surgiram novas necessidades, ma é interessante trabalhar com tipos de processadores que façam um tipo de ação específico 
- processador gráfico;
- processador ;
- processador ;
>Para analisar o desempenho dos sistemas distribuidos, utilizaremos os mesmos parametros que são utilizados para analisar arquiteturas paralelas

## Speedup e Eficiência

Uma definição largamente adotada para speedup é aumento de velocidade obtido quando se executa um determinado processo em p processadores em relação à execução deste mesmo processo em 1 processador. Desta forma, tem-se:
 
    SpeedUp = T1 / TP 

> Onde: T1 = tempo de execução em 1 processador, TP = tempo de execução em p processadores



Outra medida importatne é a eficiencia, que trata da relação entre speedup e o numero de processadores

    Eficiencia = SpeedUp / p

>Assim, no caso ideal (speedup  p), a eficiência seria máxima e teria valor 1 (100%).

Considerando agora o exercício 3)

2 (+/-).5seg = 10s \
1 (*//).10seg = 10s \
1 (^/¬).19seg = 15s
--------------------
Somando seria igual a 35s

| Processadores  | tempo [s] | SpeedUp  | Eficiência (%)  |
| :-------------: | :-------------: | :-------------: | :-------------: |
| 1  | 35  | -  | -  |
| 2  | 20  | 1,75  | 87,50  |
| 3  | 20  | 1,75  | 58,33  |
| 4  | 20  | 1,75  | 43,75  |
| 5  | 20  | 1,75  | 35,00  |

Considerando agora o exercício 4)

4 (+/-).5seg = 20s \
0 (*//).10seg = 0s \
2 (^/¬).19seg = 30s 
--------------------
Somando seria igual a 50s

| Processadores  | tempo [s] | SpeedUp  | Eficiência (%)  |
| :-------------: | :-------------: | :-------------: | :-------------: |
| 1  | 50  | -  | -  |
| 2  | 30  | 1,67  | 83,33  |
| 3  | 25  | 2,00  | 66,67  |
| 4  | 25  | 2,00  | 50,00  |
| 5  | 25  | 2,00  | 40,00  |


# Pipeline

O paralelismo físico pode ser subdividido em dois tipos: paralelismo espacial (paralelismo real) e paralelismo temporal (pipeline). O paralelismo temporal ou pipeline implica na execução de eventos sobrepostos no tempo.

Pipeline é uma técnica de hardware que permite que o processador realize a busca de uma ou mais instruções além da próxima a ser executada. Estas instruções são colocadas em uma fila de memória dentro do processador, onde aguardam para serem executadas.

* SISD - Fluxo Único de Instruções / Fluxo Único de Dados (Single Instruction Stream / Single Data Stream). 
    * Corresponde ao tradicional modelo de von Neumann. 
    * Um processador executa sequencialmente um conjunto de instruções sobre um conjunto de dados.

* MISD - Fluxo Múltiplo de Instruções / Fluxo Único de Dados (Multiple Instruction Stream / Single Data Stream). 
    * Compreende múltiplos processadores executando diferentes instruções em um único conjunto de dados.
    * Por exemplo, múltiplos filtros de frequência operando sobre um único sinal e múltiplos algoritmos de criptografia cifrando a mesma mensagem (ou arquivo).
    * Até o momento, não existem arquiteturas representates desta categoria, insto é, não há nenhuma arquitetura classificada como MISD.
    * Alguns autores consideram arquiteturas pipeline como sendo um exemplo desta classe.

* SIMD - Fluxo Único de Instruções / Fluxo Múltiplo de Dados (Single Instruction Stream / Multiple Data Stream). 
    * Compreende múltiplos processadores (escravos) sob o controle de um processador (mestre), executando simultaneamente a mesma instrução em diversos conjuntos de dados.
    * Por exemplo, arquiteturas SIMD são utilizadas para manipulação de matrizes e processamento de imagens: Os processadores recebem a mesma instrução, ao mesmo tempo, e atuam sobre diferentes fluxos de dados.
    
* MIMD - Fluxo Múltiplo de Instruções / Fluxo Múltiplo de Dados (Multiple Instruction Stream / Multiple Data Stream). 
    * Compreende múltiplos processadores executando diferentes instruções em diferentes conjuntos de dados, de maneira independente.
    * Esta classe engloba a maioria dos computadores paralelos.

graph TD;
    A-->B;
    A-->C;
    B-->D;
    C-->D;






